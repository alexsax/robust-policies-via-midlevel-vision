from visualpriors.transforms import VisualPriorPredictedLabel
import torch.utils.model_zoo
import torch
from PIL import Image
from load_data import genDS
import numpy as np
import argparse

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
import sys

'''
Argparse! Example usage:

python train.py --name insert_name --feature_task normal --batch_size 32 --num_epochs 500 --data_path /path/to/train/data/ --lr 3e-4

'''
parser = argparse.ArgumentParser(description='Train mid-level features from a dataset')
parser.add_argument('--name', type=str, required=True,help='Folder name for the output. Dont end with trailing slash')
parser.add_argument('--feature_task', type=str,required=True, help='Feature task to train. One of sobel, normal, segment_semantic, or depth')

parser.add_argument('--batch_size', type=int, default=32, help='Batch size to train with')
parser.add_argument('--num_epochs', type=int, default=200, help='Number of epochs to train with')
parser.add_argument('--lr', type=float, default=3e-4, help='Learning rate')
parser.add_argument('--data_path', type=str, default='example_path', help='Path to folders generated by robotics-rl-srl')
parser.add_argument('--model_path', type=str, default="", help='Path to model to initialize for finetuning. Default is nothing.')
parser.add_argument('--checkpoint_interval', type=int, default=20, help='')

args = parser.parse_args()

name = args.name
feature_task = args.feature_task
batch_size = args.batch_size
num_epochs = args.num_epochs
lr = args.lr

os.makedirs(name, exist_ok=True)

#redirect stdout to a log file
sys.stdout = open('%s/log.txt' % name, 'w')


trainLoader, valLoader, testLoader = genDS(batch_size=batch_size, task_name=feature_task, path = args.data_path)


device = 'cuda'

map_task_to_taskonomy = {
    "normal" : "normal",
    "sobel": "edge_texture",
    "depth": "depth_euclidean",
    "segment_semantic": "segment_semantic",
    "segment_img": "segment_semantic",
    "sobel_3d": "edge_occlusion",
    "autoencoder": "autoencoding",
    "denoise": "denoising"
}

taskonomy_feature = map_task_to_taskonomy[feature_task]
VisualPriorPredictedLabel._load_unloaded_nets([taskonomy_feature])
VisualPriorPredictedLabel.feature_task_to_net[taskonomy_feature] = VisualPriorPredictedLabel.feature_task_to_net[taskonomy_feature].to(device)
net = VisualPriorPredictedLabel.feature_task_to_net[taskonomy_feature] 

if feature_task == "segment_img":
    num_max = 5
    net.decoder.decoder_output[0] = torch.nn.Conv2d(16, num_max, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    net.decoder.decoder_output[1] = torch.nn.Identity()
    net.cuda()

if args.model_path == "random":
    def weight_reset(m):
        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
            m.reset_parameters()
    net.apply(weight_reset)
elif args.model_path:
    net.load_state_dict(torch.load(args.model_path + "/" + args.feature_task + "/bestModel.pth"))

net.encoder.eval_only = False
net.decoder.eval_only = False

for param in net.parameters():
    param.requires_grad = True

net.to(device)


optimizer = optim.Adam(net.parameters(), lr=lr)

if feature_task=="segment_img":
    loss = torch.nn.CrossEntropyLoss()
else:
    loss = nn.L1Loss()

#training loop
def train_model(model, traindl, valdl, criterion, optimizer, num_epochs=25, feature_task='normal'):
    since = time.time()

    val_loss_history = []
    # same as val loss, just ::
    epoch_loss_history = []

    best_model_wts = copy.deepcopy(model.state_dict())

    best_loss = float("inf")

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            print("Phase", phase)
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0

            if phase == 'train':
                dl = traindl
            else:
                dl = valdl

            count = 1
            for sample in dl:
                if count % 100 == 0:
                    print("On batch", count)
                count += 1

                inputs = sample['rgb'].to(device)
                targets = sample[feature_task].to(device)

                if feature_task == "denoise":
                    inputs, targets = targets, inputs

                mask = None

                if feature_task == "segment_semantic" or feature_task == "segment_img":
                    targets = targets.long()

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
            # the loss is scaled above
            epoch_loss = running_loss / len(dl)

            print('{} Loss: {:.4f}'.format(phase, epoch_loss))

            # deep copy the model
            if phase == 'val' and epoch_loss < best_loss:
                best_loss = epoch_loss
                torch.save(model.state_dict(), "%s/bestModel.pth" % name)
            if phase == 'val':
                val_loss_history.append(epoch_loss)

        #checkpoint model                
        print("Running val loss history", val_loss_history)
        print("Best val so far", best_loss)
        if epoch % args.checkpoint_interval == 0:
            torch.save(model.state_dict(), "%s/epoch_%s.pth" % (name, epoch))

        time_elapsed = time.time() - since
        print('Epoch complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best val loss: {:4f}'.format(best_loss))
    print(val_loss_history)
    return model, val_loss_history
train_model(net, trainLoader, valLoader, loss, optimizer, num_epochs, feature_task)